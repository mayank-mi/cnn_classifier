{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "array_data = np.load('C:/demo/classfier_cnn/data/full_numpy_bitmap_bicycle.npy')\n",
    "\n",
    "# Extract the first image\n",
    "first_image = array_data[16].reshape(28, 28)  # Assuming each image is 28x28 pixels (adjust as per your data)\n",
    "\n",
    "# Display the first image\n",
    "plt.imshow(first_image, cmap='gray')\n",
    "plt.axis('off')  # Optional: turn off axis numbers and ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# List of file paths for the 10 classes\n",
    "\n",
    "file_paths = [\n",
    "    'C:/demo/classfier_cnn/data/The Eiffel Tower.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_basketball.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_baseball.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bathtub.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bicycle.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_apple.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bat.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_alarm clock.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_airplane.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_book.npy'\n",
    "]\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(file_paths, num_samples=10000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        array_data = np.load(file_path)\n",
    "        # Get the first num_samples samples\n",
    "        first_samples = array_data[:num_samples]\n",
    "        data.append(first_samples)\n",
    "        # Create labels for these samples\n",
    "        labels.append(np.full((num_samples,), idx))\n",
    "    return np.vstack(data), np.concatenate(labels)\n",
    "\n",
    "# Load the data\n",
    "data, labels = load_data(file_paths)\n",
    "\n",
    "# Normalize the data\n",
    "data = data.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data if necessary (e.g., if the images are 28x28 pixels)\n",
    "data = data.reshape(-1, 28, 28, 1)  # Assuming the images are 28x28 pixels and grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400000, 28, 28, 1)\n",
      "X_test shape: (100000, 28, 28, 1)\n",
      "y_train shape: (400000,)\n",
      "y_test shape: (100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of file paths for the 10 classes\n",
    "file_paths = [\n",
    "    'C:/demo/classfier_cnn/data/The Eiffel Tower.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_basketball.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_baseball.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bathtub.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bicycle.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_apple.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_bat.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_alarm clock.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_airplane.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_book.npy'\n",
    "]\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(file_paths, num_samples=50000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        array_data = np.load(file_path)\n",
    "        # Get the first num_samples samples\n",
    "        first_samples = array_data[:num_samples]\n",
    "        data.append(first_samples)\n",
    "        # Create labels for these samples\n",
    "        labels.append(np.full((num_samples,), idx))\n",
    "    return np.vstack(data), np.concatenate(labels)\n",
    "\n",
    "# Load the data\n",
    "data, labels = load_data(file_paths)\n",
    "\n",
    "# Normalize the data\n",
    "data = data.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data if necessary (e.g., if the images are 28x28 pixels)\n",
    "data = data.reshape(-1, 28, 28, 1)  # Assuming the images are 28x28 pixels and grayscale\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "y_test\n",
    "unique_elements = np.unique(y_test)\n",
    "print(unique_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'The Eiffel Tower', 1: 'full_numpy_bitmap_basketball', 2: 'full_numpy_bitmap_baseball', 3: 'full_numpy_bitmap_bathtub', 4: 'full_numpy_bitmap_bicycle', 5: 'full_numpy_bitmap_apple', 6: 'full_numpy_bitmap_bat', 7: 'full_numpy_bitmap_alarm clock', 8: 'full_numpy_bitmap_airplane', 9: 'full_numpy_bitmap_book'}\n"
     ]
    }
   ],
   "source": [
    "# Define the class labels\n",
    "class_labels = [\n",
    "    'The Eiffel Tower',\n",
    "    'full_numpy_bitmap_basketball',\n",
    "    'full_numpy_bitmap_baseball',\n",
    "    'full_numpy_bitmap_bathtub',\n",
    "    'full_numpy_bitmap_bicycle',\n",
    "    'full_numpy_bitmap_apple',\n",
    "    'full_numpy_bitmap_bat',\n",
    "    'full_numpy_bitmap_alarm clock',\n",
    "    'full_numpy_bitmap_airplane',\n",
    "    'full_numpy_bitmap_book'\n",
    "]\n",
    "\n",
    "# Create the dictionary\n",
    "class_dict = {i: label for i, label in enumerate(class_labels)}\n",
    "\n",
    "# Print the dictionary\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after reshaping: (400000, 1, 28, 28)\n",
      "X_test shape after reshaping: (100000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_test_reshaped = np.reshape(X_test, (100000, 1, 28, 28))\n",
    "X_train_reshaped = np.reshape(X_train, (400000, 1, 28, 28))\n",
    "\n",
    "# Print the shape after reshaping\n",
    "print(\"X_train shape after reshaping:\", X_train_reshaped.shape)\n",
    "print(\"X_test shape after reshaping:\", X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test[9] shape after reshaping: (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_test_reshaped = np.reshape(X_test[9], (1, 28, 28))\n",
    "\n",
    "# Print the shape after reshaping\n",
    "print(\"X_test[9] shape after reshaping:\", X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assume X_train, y_train, X_test, y_test are already defined as numpy arrays or tensors\n",
    "\n",
    "# Convert data to tensors if they are numpy arrays\n",
    "if isinstance(X_train_reshaped, np.ndarray):\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32) #dtype=torch.float32\n",
    "if isinstance(y_train, np.ndarray):\n",
    "    y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "if isinstance(X_test_reshaped, np.ndarray):\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "if isinstance(y_test, np.ndarray):\n",
    "    y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "# Combine data and labels into TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_dataset, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "image_to_plot = X_train[1]  # Assuming you want to plot the second image (index 1)\n",
    "\n",
    "# Plot the image directly using PyTorch and matplotlib\n",
    "plt.imshow(image_to_plot.squeeze(0), cmap='gray')  # Squeeze along the channel dimension\n",
    "plt.axis('off')  # Optional: turn off axis numbers and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000017ABED5AAE0>, <torch.utils.data.dataloader.DataLoader object at 0x0000017ABED54FE0>)\n",
      "Length of train dataloader: 12500 batches of 32\n",
      "Length of test dataloader: 3125 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 28, 28, 1]), torch.Size([32]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 1, 1, 5, 0, 7, 0, 2, 4, 4, 8, 8, 3, 1, 2, 4, 9, 3, 6, 9, 1, 2, 3,\n",
       "        7, 6, 8, 3, 5, 4, 9, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'full_numpy_bitmap_basketball'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([28, 28, 1])\n",
      "Label: 0, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(452)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "# print(label,'pp')\n",
    "plt.title(class_dict[label.item()])\n",
    "plt.axis(\"Off\");\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([28, 28, 1]) -> [color_channels, height, width]\n",
      "Shape after flattening: torch.Size([28, 28]) -> [color_channels, height*width]\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten() # all nn modules function as a model (can do a forward pass)\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happened\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class doodle_class_model_02(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doodle_class_model_02(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_2 = doodle_class_model_02(input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10, # how many units in the hiden layer\n",
    "    output_shape=len(class_dict) # one for every class\n",
    ")\n",
    "model_2.to(\"cpu\") # keep model on CPU to begin with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:21,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 1.70738 | Test loss: 1.33266, Test acc: 59.82%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:01<00:20,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 1.19682 | Test loss: 1.15681, Test acc: 63.11%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:02<00:18,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 1.09591 | Test loss: 1.10516, Test acc: 64.55%\n",
      "\n",
      "Epoch: 3\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:02<00:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 1.05320 | Test loss: 1.07620, Test acc: 64.85%\n",
      "\n",
      "Epoch: 4\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:03<00:17,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 1.02609 | Test loss: 1.05690, Test acc: 65.37%\n",
      "\n",
      "Epoch: 5\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:04<00:17,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 1.00734 | Test loss: 1.04347, Test acc: 65.94%\n",
      "\n",
      "Epoch: 6\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:04<00:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.99291 | Test loss: 1.03770, Test acc: 66.29%\n",
      "\n",
      "Epoch: 7\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:05<00:15,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.98093 | Test loss: 1.02566, Test acc: 66.41%\n",
      "\n",
      "Epoch: 8\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:06<00:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.97024 | Test loss: 1.02264, Test acc: 66.08%\n",
      "\n",
      "Epoch: 9\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:07<00:14,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.96078 | Test loss: 1.01385, Test acc: 66.47%\n",
      "\n",
      "Epoch: 10\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:07<00:13,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.95356 | Test loss: 1.00486, Test acc: 66.98%\n",
      "\n",
      "Epoch: 11\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:08<00:13,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.94648 | Test loss: 0.99812, Test acc: 67.45%\n",
      "\n",
      "Epoch: 12\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:09<00:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.93951 | Test loss: 0.99558, Test acc: 67.56%\n",
      "\n",
      "Epoch: 13\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:10<00:11,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.93393 | Test loss: 0.99126, Test acc: 67.10%\n",
      "\n",
      "Epoch: 14\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:10<00:11,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.92851 | Test loss: 0.98647, Test acc: 67.77%\n",
      "\n",
      "Epoch: 15\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:11<00:10,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.92348 | Test loss: 0.98517, Test acc: 67.83%\n",
      "\n",
      "Epoch: 16\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:12<00:09,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.91871 | Test loss: 0.98219, Test acc: 67.73%\n",
      "\n",
      "Epoch: 17\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:13<00:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.91354 | Test loss: 0.98399, Test acc: 67.65%\n",
      "\n",
      "Epoch: 18\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:13<00:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.90948 | Test loss: 0.97802, Test acc: 68.06%\n",
      "\n",
      "Epoch: 19\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:14<00:07,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.90528 | Test loss: 0.97421, Test acc: 67.94%\n",
      "\n",
      "Epoch: 20\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:15<00:06,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.90135 | Test loss: 0.97211, Test acc: 68.03%\n",
      "\n",
      "Epoch: 21\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:15<00:05,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.89732 | Test loss: 0.96646, Test acc: 68.23%\n",
      "\n",
      "Epoch: 22\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:16<00:05,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.89328 | Test loss: 0.97419, Test acc: 67.83%\n",
      "\n",
      "Epoch: 23\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:17<00:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.88941 | Test loss: 0.96988, Test acc: 67.93%\n",
      "\n",
      "Epoch: 24\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:18<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.88651 | Test loss: 0.97250, Test acc: 67.30%\n",
      "\n",
      "Epoch: 25\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:18<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.88350 | Test loss: 0.95762, Test acc: 68.65%\n",
      "\n",
      "Epoch: 26\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:19<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.87968 | Test loss: 0.97616, Test acc: 67.29%\n",
      "\n",
      "Epoch: 27\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:20<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.87655 | Test loss: 0.95403, Test acc: 68.66%\n",
      "\n",
      "Epoch: 28\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n",
      "Looked at 38400/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:21<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.87328 | Test loss: 0.95392, Test acc: 68.40%\n",
      "\n",
      "Epoch: 29\n",
      "-------\n",
      "Looked at 0/40000 samples\n",
      "Looked at 12800/40000 samples\n",
      "Looked at 25600/40000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 38400/40000 samples\n",
      "\n",
      "Train loss: 0.87060 | Test loss: 0.95269, Test acc: 68.38%\n",
      "\n",
      "Train time on cpu: 21.941 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 30\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_2.train() \n",
    "        # 1. Forward pass\n",
    "        y_pred = model_2(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulatively add up the loss per epoch \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy \n",
    "    test_loss, test_acc = 0, 0 \n",
    "    model_2.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_2(X)\n",
    "           \n",
    "            # 2. Calculate loss (accumatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_2.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "        [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "        [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'doodle_class_model_02',\n",
       " 'model_loss': 0.9526905417442322,\n",
       " 'model_acc': 68.3805910543131}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_2, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:03<01:27,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 1.0201 | Test Loss: 0.7484 | Test Acc: 76.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:06<01:24,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 0.8631 | Test Loss: 0.6945 | Test Acc: 78.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:09<01:23,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.8121 | Test Loss: 0.6578 | Test Acc: 78.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:12<01:19,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.7771 | Test Loss: 0.6329 | Test Acc: 79.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:15<01:17,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | Train Loss: 0.7551 | Test Loss: 0.6193 | Test Acc: 79.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:18<01:15,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | Train Loss: 0.7274 | Test Loss: 0.6002 | Test Acc: 80.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:21<01:12,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | Train Loss: 0.7086 | Test Loss: 0.5871 | Test Acc: 81.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:24<01:09,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | Train Loss: 0.7037 | Test Loss: 0.5855 | Test Acc: 81.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:28<01:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | Train Loss: 0.6903 | Test Loss: 0.5785 | Test Acc: 81.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:31<01:03,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | Train Loss: 0.6754 | Test Loss: 0.5707 | Test Acc: 81.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:34<01:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | Train Loss: 0.6367 | Test Loss: 0.5565 | Test Acc: 82.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:37<00:56,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | Train Loss: 0.6238 | Test Loss: 0.5548 | Test Acc: 82.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:40<00:53,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | Train Loss: 0.6236 | Test Loss: 0.5492 | Test Acc: 82.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:43<00:49,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | Train Loss: 0.6188 | Test Loss: 0.5441 | Test Acc: 82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:46<00:46,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | Train Loss: 0.6094 | Test Loss: 0.5413 | Test Acc: 82.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:49<00:43,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | Train Loss: 0.6064 | Test Loss: 0.5413 | Test Acc: 82.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:53<00:40,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | Train Loss: 0.6048 | Test Loss: 0.5419 | Test Acc: 82.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:56<00:37,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | Train Loss: 0.6000 | Test Loss: 0.5379 | Test Acc: 82.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:59<00:34,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 | Train Loss: 0.5948 | Test Loss: 0.5361 | Test Acc: 82.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:02<00:31,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 | Train Loss: 0.5984 | Test Loss: 0.5346 | Test Acc: 82.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:05<00:27,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 | Train Loss: 0.5859 | Test Loss: 0.5369 | Test Acc: 82.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:08<00:25,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 | Train Loss: 0.5886 | Test Loss: 0.5356 | Test Acc: 82.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:11<00:22,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 | Train Loss: 0.5884 | Test Loss: 0.5368 | Test Acc: 82.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:15<00:18,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 | Train Loss: 0.5846 | Test Loss: 0.5360 | Test Acc: 82.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:18<00:15,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 | Train Loss: 0.5860 | Test Loss: 0.5358 | Test Acc: 82.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [01:21<00:12,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 | Train Loss: 0.5882 | Test Loss: 0.5338 | Test Acc: 82.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [01:24<00:09,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 | Train Loss: 0.5889 | Test Loss: 0.5353 | Test Acc: 82.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [01:27<00:06,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 | Train Loss: 0.5877 | Test Loss: 0.5350 | Test Acc: 82.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [01:30<00:03,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 | Train Loss: 0.5860 | Test Loss: 0.5356 | Test Acc: 82.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:33<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 | Train Loss: 0.5833 | Test Loss: 0.5328 | Test Acc: 82.75%\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class DoodleClassModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units*2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units*2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units*2, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return (correct / len(y_true)) * 100\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = DoodleClassModel(input_shape=784, hidden_units=128, output_shape=len(class_dict))\n",
    "model_2.to(\"cpu\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Data loading (assuming train_dataloader and test_dataloader are defined)\n",
    "epochs = 30\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_2.train()\n",
    "    train_loss = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "            test_pred = model_2(X)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'DoodleClassModel',\n",
       " 'model_loss': 0.532804548740387,\n",
       " 'model_acc': 82.74760383386581}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_2, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_0.state_dict(), 'moded02.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0195,  0.0034,  0.0302,  ..., -0.0030, -0.0317,  0.0128],\n",
       "        [-0.0107,  0.0221, -0.0158,  ..., -0.0121,  0.0042,  0.0318],\n",
       "        [-0.0106,  0.0342,  0.0240,  ...,  0.0091,  0.0174,  0.0041]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doodle_class(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_0.state_dict(), 'mod01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the sample image\n",
    "# sample_image_path = 'path_to_your_sample_image.jpg'  # Replace with your actual image path\n",
    "# sample_image = Image.open(sample_image_path)\n",
    "\n",
    "array_data = np.load('C:/demo/classfier_cnn/data/full_numpy_bitmap_bat.npy')\n",
    "# Extract the first image\n",
    "input_tensor = array_data[6].reshape(28, 28,1)\n",
    "\n",
    "# Display the first image\n",
    "plt.imshow(input_tensor, cmap='gray')\n",
    "plt.axis('off')  # Optional: turn off axis numbers and ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample_image(image_array):\n",
    "    # Normalize the image\n",
    "    image_array = image_array.astype('float32') / 255.0\n",
    "    # Reshape the image to (1, 28, 28, 1) if it's a single image\n",
    "    image_array = np.reshape(image_array, (1, 1, 28, 28))\n",
    "    # Convert to torch tensor\n",
    "    image_tensor = torch.tensor(image_array, dtype=torch.float32)\n",
    "    # Flatten the image tensor to shape (1, 784)\n",
    "    image_tensor = image_tensor.view(1, -1)\n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: full_numpy_bitmap_airplane\n",
      "Predicted class index: 8\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the sample image\n",
    "sample_image_tensor = preprocess_sample_image(input_tensor)\n",
    "\n",
    "# Make a prediction with the loaded model\n",
    "with torch.no_grad():\n",
    "    output = model_2(sample_image_tensor)\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "# Print the predicted class\n",
    "\n",
    "print(f\"Predicted class label: {class_dict[predicted_class]}\")\n",
    "print(f\"Predicted class index: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_sample_image(image_array):\n",
    "    # Normalize the image\n",
    "    image_array = image_array.astype('float32') / 255.0\n",
    "    # Reshape the image to (1, 28, 28, 1) if it's a single image\n",
    "    image_array = np.reshape(image_array, (1, 1, 28, 28))\n",
    "    # Convert to torch tensor\n",
    "    image_tensor = torch.tensor(image_array, dtype=torch.float32)\n",
    "    \n",
    "    # Check if CUDA (GPU) is available and move tensor to CUDA device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Flatten the image tensor to shape (1, 784)\n",
    "    image_tensor = image_tensor.view(1, -1)\n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:06<03:00,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.9520 | Test Loss: 0.6783 | Test Acc: 78.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:12<02:54,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 0.8144 | Test Loss: 0.6219 | Test Acc: 79.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:19<02:52,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.7732 | Test Loss: 0.5890 | Test Acc: 81.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:25<02:45,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.7448 | Test Loss: 0.5762 | Test Acc: 81.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:31<02:38,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | Train Loss: 0.7228 | Test Loss: 0.5520 | Test Acc: 82.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:38<02:32,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | Train Loss: 0.7066 | Test Loss: 0.5426 | Test Acc: 82.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:44<02:26,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | Train Loss: 0.6964 | Test Loss: 0.5346 | Test Acc: 82.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:50<02:19,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | Train Loss: 0.6838 | Test Loss: 0.5311 | Test Acc: 82.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:57<02:17,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | Train Loss: 0.6738 | Test Loss: 0.5173 | Test Acc: 83.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [01:07<02:31,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | Train Loss: 0.6646 | Test Loss: 0.5138 | Test Acc: 83.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [01:18<02:44,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | Train Loss: 0.6326 | Test Loss: 0.4990 | Test Acc: 83.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [01:30<02:50,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | Train Loss: 0.6265 | Test Loss: 0.4970 | Test Acc: 84.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [01:41<02:49,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | Train Loss: 0.6169 | Test Loss: 0.4955 | Test Acc: 83.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [01:52<02:45, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | Train Loss: 0.6197 | Test Loss: 0.4914 | Test Acc: 84.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [02:03<02:38, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | Train Loss: 0.6144 | Test Loss: 0.4916 | Test Acc: 84.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [02:14<02:30, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | Train Loss: 0.6110 | Test Loss: 0.4975 | Test Acc: 84.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [02:25<02:21, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | Train Loss: 0.6076 | Test Loss: 0.4882 | Test Acc: 84.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [02:32<01:54,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | Train Loss: 0.6052 | Test Loss: 0.4920 | Test Acc: 84.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [02:38<01:34,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 | Train Loss: 0.6008 | Test Loss: 0.4882 | Test Acc: 84.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [02:45<01:19,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 | Train Loss: 0.5998 | Test Loss: 0.4843 | Test Acc: 84.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [02:51<01:08,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 | Train Loss: 0.6001 | Test Loss: 0.4882 | Test Acc: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [02:58<00:57,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 | Train Loss: 0.5965 | Test Loss: 0.4838 | Test Acc: 84.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [03:04<00:49,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 | Train Loss: 0.5962 | Test Loss: 0.4838 | Test Acc: 84.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [03:10<00:40,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 | Train Loss: 0.5999 | Test Loss: 0.4842 | Test Acc: 84.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [03:17<00:34,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 | Train Loss: 0.5949 | Test Loss: 0.4906 | Test Acc: 84.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [03:24<00:27,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 | Train Loss: 0.5928 | Test Loss: 0.4827 | Test Acc: 84.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [03:31<00:20,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 | Train Loss: 0.5944 | Test Loss: 0.4823 | Test Acc: 84.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [03:37<00:13,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 | Train Loss: 0.5983 | Test Loss: 0.4959 | Test Acc: 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [03:44<00:06,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 | Train Loss: 0.5956 | Test Loss: 0.4862 | Test Acc: 84.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:51<00:00,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 | Train Loss: 0.5938 | Test Loss: 0.4946 | Test Acc: 84.30%\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class DoodleClassModel03(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units*2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units*2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units*2, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return (correct / len(y_true)) * 100\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = DoodleClassModel(input_shape=784, hidden_units=128, output_shape=len(class_dict))\n",
    "model_2.to(\"cpu\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Data loading (assuming train_dataloader and test_dataloader are defined)\n",
    "epochs = 30\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_2.train()\n",
    "    train_loss = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "            test_pred = model_2(X)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 38\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;66;03m# only works when model was created with a class\u001b[39;00m\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate model 0 results on test dataset\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m model_0_results \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_fn\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m model_0_results\n",
      "Cell \u001b[1;32mIn[41], line 22\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# Make predictions with the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Accumulate the loss and accuracy values per batch\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[30], line 24\u001b[0m, in \u001b[0;36mDoodleClassModel03.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_2, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\test001\\ttt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "  2%|▏         | 1/50 [00:08<07:00,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.8905 | Test Loss: 0.6194 | Test Acc: 80.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:17<06:50,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.7554 | Test Loss: 0.5672 | Test Acc: 82.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:25<06:43,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.7025 | Test Loss: 0.5422 | Test Acc: 82.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:31<08:12, 10.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     58\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 59\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    177\u001b[0m         group,\n\u001b[0;32m    178\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         state_steps,\n\u001b[0;32m    185\u001b[0m     )\n\u001b[1;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\adamw.py:415\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    412\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    418\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class DoodleClassModel03(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units*2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units*2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units*2, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return (correct / len(y_true)) * 100\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = DoodleClassModel03(input_shape=784, hidden_units=256, output_shape=len(class_dict))  # Increased hidden units\n",
    "model_2.to(\"cpu\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model_2.parameters(), lr=0.001, weight_decay=1e-5)  # Using AdamW optimizer\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)  # Reduce LR on plateau\n",
    "\n",
    "# Data loading (assuming train_dataloader and test_dataloader are defined)\n",
    "epochs = 50  # Increase the number of epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_2.train()\n",
    "    train_loss = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "            test_pred = model_2(X)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    scheduler.step(test_loss)  # Update the scheduler\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 58\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[0;32m     60\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 24\u001b[0m, in \u001b[0;36mDoodleClassModel03.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\test001\\ttt\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class DoodleClassModel03(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units*2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_units*2),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=hidden_units*2, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return (correct / len(y_true)) * 100\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = DoodleClassModel03(input_shape=784, hidden_units=512, output_shape=len(class_dict)) #hidden_units=256\n",
    "model_2.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model_2.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "# Data loading (assuming train_dataloader and test_dataloader are defined)\n",
    "epochs = 3\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_2.train()\n",
    "    train_loss = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model_2(X)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    scheduler.step(test_loss)  # Update the scheduler\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0084, -0.0058,  0.0228,  ...,  0.0293,  0.0206, -0.0119],\n",
       "        [ 0.0009,  0.0123,  0.0233,  ..., -0.0127, -0.0286,  0.0204],\n",
       "        [-0.0308,  0.0149, -0.0223,  ...,  0.0130, -0.0236, -0.0194]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8812e-02, -3.5414e-02,  1.8694e-02,  8.5192e-03, -1.8164e-02,\n",
       "         3.4418e-02, -1.6152e-02,  2.4134e-02,  1.8119e-02, -2.9943e-02,\n",
       "         2.3034e-02, -3.2838e-02, -1.9786e-02, -5.9541e-03, -2.4073e-02,\n",
       "         3.4890e-02, -7.1636e-03,  1.4185e-02, -3.1890e-02,  2.0560e-02,\n",
       "        -1.1099e-02, -2.7167e-02,  5.2222e-03,  1.7302e-02,  3.0907e-02,\n",
       "        -2.1814e-02, -1.7575e-02,  6.8665e-03,  9.6879e-03,  1.3731e-02,\n",
       "         1.9603e-02, -8.0983e-03,  1.9842e-02,  2.6332e-02, -9.3293e-03,\n",
       "         2.5409e-02,  1.7449e-02,  3.1502e-02, -2.0295e-02, -1.7636e-02,\n",
       "        -1.0326e-02,  1.8117e-03,  2.1436e-02, -2.0388e-02,  1.7880e-02,\n",
       "        -1.2799e-02,  2.1575e-02, -1.6956e-03, -3.1289e-02, -1.9652e-02,\n",
       "        -2.5848e-02,  1.7713e-02, -2.3948e-02, -2.9757e-03,  7.7056e-03,\n",
       "        -1.9586e-02,  1.0303e-02, -3.4872e-02, -2.5554e-02, -3.2362e-02,\n",
       "        -1.0803e-02, -1.3011e-02,  5.1140e-03, -6.6041e-03,  1.6789e-02,\n",
       "         3.2743e-02,  1.2814e-02, -1.4070e-02, -3.3442e-02,  1.2936e-02,\n",
       "        -1.7695e-02,  1.8174e-02,  2.3874e-02,  1.3776e-02,  3.3511e-02,\n",
       "         3.3921e-02,  7.5621e-03, -2.6023e-02,  3.1909e-02, -1.6946e-02,\n",
       "        -1.6870e-02,  2.9885e-02,  2.7672e-02,  1.0791e-02,  2.2387e-03,\n",
       "        -3.0042e-02, -3.7073e-03,  3.4255e-02,  9.0950e-03,  3.0578e-03,\n",
       "        -7.4161e-03, -1.2457e-02,  2.1287e-02,  2.2024e-03,  2.3235e-02,\n",
       "        -6.3214e-03,  1.5604e-02,  1.4742e-02,  5.6951e-03,  2.2442e-02,\n",
       "         2.2380e-02,  3.3104e-02,  2.7456e-02, -9.1320e-03, -3.0236e-02,\n",
       "         6.5292e-03, -3.1172e-04, -9.3152e-03, -5.9805e-03,  1.6797e-03,\n",
       "         2.6058e-02,  1.1134e-02, -1.2682e-02, -1.4687e-02, -8.8440e-03,\n",
       "        -1.3804e-02,  3.2115e-02,  1.8916e-02,  3.2249e-02,  1.1406e-04,\n",
       "         7.2025e-03,  1.2384e-02, -3.3805e-02,  3.1892e-03, -2.3889e-03,\n",
       "        -2.0023e-02, -2.7712e-02,  3.1617e-02,  2.9038e-02,  1.6552e-02,\n",
       "         3.4080e-02, -1.4493e-02, -6.1687e-03,  1.3522e-02, -5.9009e-03,\n",
       "        -7.0084e-03, -2.9520e-02,  9.5950e-03, -2.1583e-02,  1.2988e-03,\n",
       "         3.4821e-02, -1.0993e-02, -1.1257e-02,  2.1547e-02, -1.3130e-02,\n",
       "        -3.0671e-03,  3.3348e-02, -1.4642e-02, -2.5550e-02, -1.9987e-02,\n",
       "        -9.9016e-03, -1.6946e-02, -1.8533e-02,  1.4427e-02,  6.0692e-03,\n",
       "        -1.1431e-02, -2.7747e-02, -1.1245e-02, -1.5073e-02, -1.1622e-02,\n",
       "        -3.2219e-02,  7.6939e-03, -2.6240e-02, -2.7814e-02, -2.9180e-02,\n",
       "         1.4907e-02, -2.1501e-02, -1.4741e-02,  2.7994e-02,  1.8963e-02,\n",
       "         2.0478e-02, -3.3911e-02, -2.5611e-02, -1.3483e-02,  2.9503e-02,\n",
       "         3.6536e-03, -2.6711e-02,  2.2364e-04, -2.7738e-02, -7.8250e-03,\n",
       "        -9.8205e-03,  3.0916e-02,  1.1062e-02, -6.2275e-03,  6.0332e-03,\n",
       "        -1.0309e-02,  1.4032e-02,  1.4127e-02,  9.5909e-03, -1.3921e-02,\n",
       "         3.0470e-02, -5.1561e-03, -1.3904e-02,  2.2368e-02,  2.9109e-02,\n",
       "         3.5541e-02,  1.0581e-02, -1.2175e-02,  1.8139e-02,  3.0641e-02,\n",
       "        -3.5030e-02, -4.4245e-03, -2.4356e-02,  6.6557e-03,  1.4771e-02,\n",
       "        -7.3781e-03, -2.9878e-03,  1.6075e-02, -6.0025e-03, -2.9992e-02,\n",
       "         2.8576e-02, -1.7976e-02, -3.9235e-03,  3.3688e-03, -2.1463e-03,\n",
       "        -3.3596e-02,  1.6386e-02, -1.6223e-02, -1.8524e-02,  8.5327e-03,\n",
       "        -1.8638e-02, -1.6506e-02, -1.2034e-02, -1.3417e-02, -1.4916e-02,\n",
       "        -9.6316e-03,  9.2813e-03, -2.8901e-02, -2.1617e-02,  5.2112e-04,\n",
       "         4.9667e-03,  1.9725e-02, -2.5087e-02,  1.1400e-02,  2.0300e-02,\n",
       "         1.9831e-02, -3.3265e-02, -1.3629e-02, -3.0699e-02, -2.2600e-02,\n",
       "         1.9892e-02, -5.3328e-03,  1.5168e-02, -2.0965e-02,  5.4271e-03,\n",
       "        -2.1602e-02,  1.7853e-02, -1.5621e-02, -8.9557e-03, -3.0987e-02,\n",
       "         1.1798e-04,  3.3910e-02,  1.7335e-02, -1.9055e-02,  4.8031e-04,\n",
       "        -3.9160e-03, -2.8753e-02,  2.8003e-02,  5.7574e-04,  7.5213e-03,\n",
       "        -1.4422e-02, -1.6711e-02,  5.8889e-03,  1.3204e-02,  8.0106e-03,\n",
       "        -1.7212e-02,  3.4675e-02, -5.2573e-03, -2.1872e-02, -1.6704e-02,\n",
       "         3.5158e-02,  1.7211e-06, -4.8480e-03, -1.4863e-02, -9.3623e-03,\n",
       "        -3.0080e-02, -2.8382e-02,  2.0903e-02,  3.0552e-02,  3.4082e-02,\n",
       "        -2.5784e-02,  1.9317e-02, -2.2106e-02,  2.1306e-02,  2.5770e-02,\n",
       "         2.7638e-02,  2.5716e-02,  2.2342e-02,  6.9513e-04,  1.6410e-02,\n",
       "        -1.2778e-02,  1.5551e-02, -1.1479e-02, -5.9969e-04, -3.1085e-02,\n",
       "        -9.3384e-03, -1.8781e-02, -1.2047e-02, -2.2807e-02, -3.2123e-02,\n",
       "         2.3256e-03,  2.3178e-02,  3.2527e-02,  2.0841e-02, -1.8512e-02,\n",
       "        -3.5322e-02,  1.3547e-02,  2.0011e-02, -3.0661e-02,  1.2807e-02,\n",
       "         3.0196e-02,  2.1634e-03, -2.1516e-02,  2.9281e-02,  1.5251e-02,\n",
       "         2.3650e-02, -2.4153e-02,  2.0784e-02, -2.4395e-02,  3.5339e-02,\n",
       "        -1.5132e-02,  2.1520e-02,  7.1515e-03,  9.4647e-03, -5.4770e-03,\n",
       "         1.4669e-02, -1.4885e-02, -3.3664e-02, -1.3722e-02,  2.7984e-02,\n",
       "        -9.4025e-03,  1.1226e-02, -1.3205e-02,  2.6791e-02,  2.1375e-02,\n",
       "         1.2608e-02, -1.8256e-02, -2.9183e-02,  1.3446e-03, -2.0952e-02,\n",
       "         2.9364e-02, -3.4321e-02,  1.5960e-02,  3.5604e-02,  1.7887e-02,\n",
       "         1.2178e-02, -3.4362e-02,  3.4353e-02, -6.1088e-03, -3.3372e-02,\n",
       "         3.5256e-02, -1.4533e-02, -2.5267e-03,  3.2689e-02, -2.4757e-02,\n",
       "        -2.5268e-02,  5.8078e-03, -4.7805e-03,  8.2265e-03, -2.9954e-02,\n",
       "         1.0681e-03, -1.5884e-02, -1.7557e-02, -3.2701e-02,  1.8936e-02,\n",
       "         6.8799e-03, -3.0194e-02,  2.8341e-02,  1.0772e-02,  6.6273e-03,\n",
       "        -2.0969e-02,  5.3859e-03,  3.4412e-02,  2.4496e-02, -2.7817e-02,\n",
       "         3.2601e-02,  2.7682e-03,  1.7177e-02,  2.7738e-02,  3.0447e-02,\n",
       "        -2.7841e-02,  3.1274e-02, -2.4256e-02,  2.6774e-03, -2.4956e-02,\n",
       "        -7.8298e-03, -1.6230e-03, -4.2727e-03, -5.6420e-03,  2.8168e-03,\n",
       "         3.5229e-02,  2.0750e-02,  1.9981e-02,  1.4295e-02,  2.7649e-02,\n",
       "        -1.6482e-03,  2.8397e-03,  7.3499e-03, -3.1148e-02, -2.8770e-02,\n",
       "         4.3786e-03, -1.3973e-02, -6.5535e-04, -8.1950e-03,  5.5594e-03,\n",
       "         2.3236e-02, -1.1844e-02,  2.8602e-02,  2.8199e-02, -2.7411e-02,\n",
       "        -2.7580e-02, -2.8896e-02, -1.9572e-02, -1.3903e-02, -2.6882e-03,\n",
       "        -8.6854e-03, -1.8045e-02, -1.1346e-02, -1.2919e-02,  3.5037e-02,\n",
       "        -1.3237e-02, -2.5571e-02,  1.4846e-02, -2.0629e-03,  2.7342e-02,\n",
       "         2.2315e-02,  3.2812e-02, -2.6156e-02,  2.2959e-02,  2.9973e-02,\n",
       "        -1.7637e-02,  3.2828e-02,  2.6773e-02,  3.9111e-04,  1.7220e-02,\n",
       "        -1.2486e-02, -3.1149e-02,  9.0279e-03,  1.0647e-02, -2.3341e-02,\n",
       "         1.7321e-02, -3.0508e-02,  3.0737e-02,  3.4585e-02,  9.7235e-03,\n",
       "        -2.2408e-02,  1.7381e-02,  6.0863e-03,  9.7114e-03,  1.1738e-02,\n",
       "         2.7191e-02, -1.5351e-02, -8.0338e-03,  9.7395e-03,  3.8915e-03,\n",
       "         2.8799e-02, -1.8759e-02, -1.3006e-03,  6.6733e-03, -9.4853e-03,\n",
       "         2.4347e-02,  3.9065e-03, -3.3008e-02, -3.8691e-03, -1.6198e-02,\n",
       "         3.4704e-03, -4.1506e-03, -3.5426e-02, -6.5080e-03, -3.4207e-03,\n",
       "        -1.0531e-02,  3.2814e-02, -7.7928e-03,  2.2943e-02,  8.8471e-03,\n",
       "        -3.0148e-02,  8.3924e-03,  2.9598e-02, -2.3361e-02, -2.3085e-02,\n",
       "         3.4959e-02,  2.8697e-02, -1.9925e-02,  2.1491e-02, -4.5690e-03,\n",
       "        -3.5212e-02,  2.6833e-03,  1.1539e-02, -1.0713e-02,  1.2424e-02,\n",
       "        -3.0539e-02,  2.4751e-02,  3.0448e-02,  1.9695e-02,  6.0533e-03,\n",
       "         1.1762e-02, -2.5841e-02, -8.9241e-03, -3.4096e-03, -1.9875e-02,\n",
       "        -2.6379e-02,  2.4022e-02,  2.4237e-02, -3.2435e-02,  1.1365e-02,\n",
       "         1.4529e-02,  3.3927e-02,  2.0663e-02,  3.2833e-02, -1.1692e-02,\n",
       "         2.5014e-02,  2.9050e-02, -3.3726e-02, -2.8668e-02,  7.2288e-03,\n",
       "         1.9501e-02, -1.7743e-02,  3.9334e-03, -5.1849e-05,  9.0396e-03,\n",
       "        -1.9191e-02,  2.0144e-02,  2.3750e-02, -2.4781e-02,  3.4598e-04,\n",
       "         9.9093e-05,  1.1468e-02,  3.3271e-02,  1.0474e-02, -8.1151e-03,\n",
       "         3.2076e-02, -1.3590e-02, -1.0370e-02,  2.4384e-03, -2.7197e-02,\n",
       "         3.8863e-03, -2.4231e-02,  3.6722e-03,  3.4217e-03,  4.9436e-03,\n",
       "        -3.0118e-02, -3.3921e-02,  1.6433e-02,  3.0628e-02, -3.1692e-02,\n",
       "         1.3228e-02, -2.6290e-02,  2.2390e-03,  3.3227e-02,  2.7094e-02,\n",
       "        -2.6112e-02,  2.2092e-02,  1.8654e-02, -5.4780e-05,  3.4597e-02,\n",
       "        -1.4185e-02, -8.3113e-03, -1.8051e-02,  5.1392e-03,  9.4567e-03,\n",
       "         2.8457e-03, -2.0094e-02, -1.6077e-02,  1.2148e-02, -3.1315e-02,\n",
       "        -5.5619e-03, -7.9113e-04, -1.4470e-02,  1.2997e-02,  2.3019e-03,\n",
       "         2.5074e-02, -3.1718e-03, -2.2541e-02,  2.5234e-02,  4.9875e-03,\n",
       "        -1.0229e-02, -2.3539e-02,  8.3710e-03, -3.4063e-02,  9.4064e-03,\n",
       "         1.7659e-02, -3.1329e-02, -2.3381e-02, -2.5676e-02,  3.0018e-02,\n",
       "         3.0361e-02,  2.2357e-03,  3.3529e-02, -1.1939e-02, -3.4672e-02,\n",
       "         1.2475e-02,  1.2652e-02,  3.5014e-02, -1.0338e-05,  2.7371e-02,\n",
       "         2.1892e-02,  2.5849e-02, -3.5440e-02,  2.9409e-02, -3.0445e-02,\n",
       "         3.2018e-02, -1.4800e-03, -3.1651e-02,  9.9319e-03, -7.2695e-03,\n",
       "        -3.2078e-02, -1.2948e-02,  3.6823e-03,  2.7816e-02, -1.0980e-02,\n",
       "         2.1213e-02,  4.4724e-03,  1.2039e-03,  6.8338e-03, -2.3438e-02,\n",
       "        -2.9686e-02, -1.1222e-02, -3.3281e-02, -1.6655e-02,  1.6431e-03,\n",
       "        -2.3522e-02, -1.4814e-02, -6.4174e-03, -4.1144e-03, -1.9715e-02,\n",
       "         1.7161e-03, -5.0129e-03,  1.0214e-02,  1.6131e-03, -1.7835e-02,\n",
       "        -1.2296e-02, -4.1163e-04, -2.2285e-02,  2.7959e-03, -2.5216e-03,\n",
       "         1.3856e-02,  8.4523e-03,  2.6728e-02, -1.1773e-03, -2.6389e-02,\n",
       "         1.5965e-02, -2.4137e-02, -4.9090e-03, -1.1564e-02, -1.3552e-02,\n",
       "        -1.3214e-02,  3.2819e-02,  2.0445e-02,  9.8978e-03,  3.3534e-02,\n",
       "        -3.2365e-02,  5.7631e-03,  2.2863e-02,  2.3725e-02, -2.8423e-02,\n",
       "         1.2710e-02, -2.0346e-02, -1.3955e-03, -7.4525e-03, -2.9820e-02,\n",
       "        -3.4068e-02, -2.3496e-02,  1.6206e-02,  1.6337e-02, -3.1063e-02,\n",
       "        -1.3412e-02,  5.8337e-04, -3.0878e-02,  2.0123e-02,  3.2348e-02,\n",
       "         6.3165e-03, -2.6536e-02,  8.3281e-03,  1.2965e-02,  2.8280e-02,\n",
       "        -1.9002e-02, -3.1997e-02,  1.5691e-02,  2.2234e-03, -1.1637e-02,\n",
       "        -1.4965e-02, -1.8415e-02,  2.8911e-02, -6.1621e-03,  2.5757e-02,\n",
       "         3.1880e-02,  4.5241e-03,  7.6078e-03, -2.4323e-03,  2.4529e-02,\n",
       "        -3.2182e-02,  1.4203e-02, -5.8189e-03,  1.6308e-02, -1.5907e-04,\n",
       "        -1.3224e-02, -3.8554e-03,  1.9285e-02, -2.4805e-02, -2.2575e-02,\n",
       "        -7.9999e-03, -1.2954e-02,  1.4030e-02,  2.4035e-02, -3.8249e-03,\n",
       "         3.3770e-02, -1.4922e-02, -2.0041e-02, -1.5989e-02, -2.4606e-02,\n",
       "        -2.5033e-02, -3.1822e-02, -3.1653e-02,  9.3214e-03,  2.1781e-02,\n",
       "         3.3530e-02,  3.0421e-02, -2.0569e-03,  6.9302e-03, -2.1369e-02,\n",
       "         1.3804e-02, -3.4244e-02,  1.6845e-02,  6.5506e-03,  1.0975e-02,\n",
       "         1.3077e-02, -1.6397e-02,  3.0647e-02,  1.7045e-02,  2.3461e-02,\n",
       "         4.7171e-03,  2.2428e-02,  2.4036e-02,  1.6187e-02,  2.7206e-02,\n",
       "        -6.4778e-03,  2.3483e-02,  8.2285e-03,  2.1489e-02,  3.4786e-02,\n",
       "         8.0870e-03, -1.3256e-02, -3.5534e-03,  1.0055e-02,  6.0218e-03,\n",
       "        -9.7561e-03,  2.7983e-02,  2.1457e-02, -2.2184e-02, -2.9101e-03,\n",
       "        -3.4283e-03, -2.2383e-02,  5.2091e-03, -1.0964e-02, -1.8438e-02,\n",
       "        -1.1484e-02, -1.2734e-02,  3.4166e-02,  1.3699e-02,  3.5147e-02,\n",
       "         9.7927e-03,  8.0868e-03,  1.4682e-02,  6.1297e-03, -2.8028e-02,\n",
       "        -2.1120e-02, -8.6528e-03,  5.3690e-04,  1.3454e-02,  1.3752e-02,\n",
       "         2.8333e-02,  7.2705e-03, -1.2189e-02, -2.6858e-02, -2.6158e-02,\n",
       "        -2.1333e-02,  1.0772e-02,  1.9295e-02,  3.1247e-02, -1.1297e-02,\n",
       "        -2.8172e-03, -1.0606e-02, -1.3050e-04,  1.1464e-02], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(next(model_2.parameters())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2.state_dict(), 'model002_50k_1st_512_hid.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'DoodleClassModel03',\n",
       " 'model_loss': 0.35276123881340027,\n",
       " 'model_acc': 89.997}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Move data to the device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Move model to the device\n",
    "model_2.to(device)\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_2, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'model_name': 'DoodleClassModel03',\n",
    " 'model_loss': 0.3829771876335144,\n",
    " 'model_acc': 88.561}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 28, 28, 1])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classfier_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
