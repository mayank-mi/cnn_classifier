{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79895 files belonging to 8 classes.\n",
      "Using 63916 files for training.\n",
      "Found 79895 files belonging to 8 classes.\n",
      "Using 15979 files for validation.\n",
      "['airplane', 'alarm_clock', 'apple', 'basketball', 'bat', 'bathtub', 'book', 'cycle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\test001\\ttt\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - accuracy: 0.5739 - loss: 1.2106 - val_accuracy: 0.8096 - val_loss: 0.6075 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.6344 - val_accuracy: 0.8445 - val_loss: 0.5058 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8164 - loss: 0.5606 - val_accuracy: 0.8561 - val_loss: 0.4884 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.5091 - val_accuracy: 0.8765 - val_loss: 0.4053 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.4776 - val_accuracy: 0.8825 - val_loss: 0.3998 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.4608 - val_accuracy: 0.8899 - val_loss: 0.3583 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.4436 - val_accuracy: 0.8877 - val_loss: 0.3694 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.4328 - val_accuracy: 0.8810 - val_loss: 0.4011 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.4258 - val_accuracy: 0.8887 - val_loss: 0.3613 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.3964 - val_accuracy: 0.9018 - val_loss: 0.3141 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3754 - val_accuracy: 0.9054 - val_loss: 0.3178 - learning_rate: 2.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.3650 - val_accuracy: 0.9078 - val_loss: 0.2998 - learning_rate: 2.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.3562 - val_accuracy: 0.9071 - val_loss: 0.3051 - learning_rate: 2.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3587 - val_accuracy: 0.9086 - val_loss: 0.2999 - learning_rate: 2.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.3536 - val_accuracy: 0.9102 - val_loss: 0.2938 - learning_rate: 2.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8892 - loss: 0.3509 - val_accuracy: 0.9103 - val_loss: 0.2939 - learning_rate: 2.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.3496 - val_accuracy: 0.9113 - val_loss: 0.2930 - learning_rate: 2.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.3453 - val_accuracy: 0.9081 - val_loss: 0.2962 - learning_rate: 2.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3400 - val_accuracy: 0.9106 - val_loss: 0.2904 - learning_rate: 2.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8935 - loss: 0.3353 - val_accuracy: 0.9116 - val_loss: 0.2886 - learning_rate: 2.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3352 - val_accuracy: 0.9134 - val_loss: 0.2851 - learning_rate: 2.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.3377 - val_accuracy: 0.9121 - val_loss: 0.2832 - learning_rate: 2.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8937 - loss: 0.3304 - val_accuracy: 0.9100 - val_loss: 0.2901 - learning_rate: 2.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8947 - loss: 0.3298 - val_accuracy: 0.9118 - val_loss: 0.2880 - learning_rate: 2.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.3321 - val_accuracy: 0.9153 - val_loss: 0.2815 - learning_rate: 2.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.3317 - val_accuracy: 0.9158 - val_loss: 0.2829 - learning_rate: 2.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8954 - loss: 0.3288 - val_accuracy: 0.9143 - val_loss: 0.2792 - learning_rate: 2.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.3260 - val_accuracy: 0.9156 - val_loss: 0.2759 - learning_rate: 2.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.3239 - val_accuracy: 0.9131 - val_loss: 0.2862 - learning_rate: 2.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m1998/1998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8975 - loss: 0.3267 - val_accuracy: 0.9123 - val_loss: 0.2852 - learning_rate: 2.0000e-04\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpfjlyc720\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpfjlyc720\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpfjlyc720'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='keras_tensor_220')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2231154712912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154717712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154709648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154719248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244289168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243126928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243127312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244287824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244277648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243126544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243128080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243128464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243131728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load the data\n",
    "data_dir = 'C:/test001/ttt/data'\n",
    "batch_size = 32\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create the model\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    data_augmentation,\n",
    "    Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the model as a TFLite file\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('C:/test001/ttt/cnn_classifier/ml_model/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">334,170</span> (1.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m334,170\u001b[0m (1.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,240</span> (434.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,240\u001b[0m (434.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,482</span> (869.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m222,482\u001b[0m (869.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpo8kzgyk8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpo8kzgyk8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Mind\\AppData\\Local\\Temp\\tmpo8kzgyk8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='keras_tensor_220')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2231154712912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154717712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154709648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154719248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2231154718288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244289168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243126928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243127312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244287824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232244277648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243126544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243128080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243128464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243129616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243130384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2232243131728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model saved as model.tflite\n"
     ]
    }
   ],
   "source": [
    "# Save the model as a TFLite file\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model saved as model.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bat'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = ['airplane',\n",
    " 'alarm_clock',\n",
    " 'apple',\n",
    " 'basketball',\n",
    " 'bat',\n",
    " 'bathtub',\n",
    " 'book',\n",
    " 'cycle']\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/ios_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Define the image path\n",
    "img_path = 'C:/test001/ttt/cnn_classifier/iamges/image_4.png'\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Create a batch axis\n",
    "    img_array = img_array # Normalize the image\n",
    "    return img_array\n",
    "\n",
    "img_array = load_and_preprocess_image(img_path)\n",
    "\n",
    "# Set the tensor to point to the input data to be inferred\n",
    "interpreter.set_tensor(input_details[0]['index'], img_array)\n",
    "\n",
    "# Run the inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "predicted_class = np.argmax(output_data, axis=1)\n",
    "class_names[predicted_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.2884495,  -6.8941965,  -6.5475106, -11.686626 ,  17.954012 ,\n",
       "         -6.8227386,  -8.477249 ,  -7.1611204]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_keras_tensor_220:0',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28,  3]),\n",
       "  'shape_signature': array([-1, 28, 28,  3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names1 = ['airplane',\n",
    " 'alarm_clock',\n",
    " 'apple',\n",
    " 'basketball',\n",
    " 'bat',\n",
    " 'bathtub',\n",
    " 'book',\n",
    " 'cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "-------------------\n",
      "Inputs:\n",
      "Name: serving_default_keras_tensor_220:0\n",
      "Shape: [ 1 28 28  3]\n",
      "Type: <class 'numpy.float32'>\n",
      "\n",
      "Outputs:\n",
      "Name: StatefulPartitionedCall_1:0\n",
      "Shape: [1 8]\n",
      "Type: <class 'numpy.float32'>\n",
      "\n",
      "Layers:\n",
      "Layer 1:\n",
      "Name: serving_default_keras_tensor_220:0\n",
      "Index: 0\n",
      "Shape: [ 1 28 28  3]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 2:\n",
      "Name: arith.constant\n",
      "Index: 1\n",
      "Shape: [128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 3:\n",
      "Name: arith.constant1\n",
      "Index: 2\n",
      "Shape: [64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 4:\n",
      "Name: arith.constant2\n",
      "Index: 3\n",
      "Shape: [32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 5:\n",
      "Name: arith.constant3\n",
      "Index: 4\n",
      "Shape: [128   3   3  64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 6:\n",
      "Name: arith.constant4\n",
      "Index: 5\n",
      "Shape: [64  3  3 32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 7:\n",
      "Name: arith.constant5\n",
      "Index: 6\n",
      "Shape: [  8 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 8:\n",
      "Name: arith.constant6\n",
      "Index: 7\n",
      "Shape: [128 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 9:\n",
      "Name: arith.constant7\n",
      "Index: 8\n",
      "Shape: [128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 10:\n",
      "Name: arith.constant8\n",
      "Index: 9\n",
      "Shape: [128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 11:\n",
      "Name: arith.constant9\n",
      "Index: 10\n",
      "Shape: [32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 12:\n",
      "Name: arith.constant10\n",
      "Index: 11\n",
      "Shape: [32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 13:\n",
      "Name: arith.constant11\n",
      "Index: 12\n",
      "Shape: [64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 14:\n",
      "Name: arith.constant12\n",
      "Index: 13\n",
      "Shape: [64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 15:\n",
      "Name: arith.constant13\n",
      "Index: 14\n",
      "Shape: [128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 16:\n",
      "Name: arith.constant14\n",
      "Index: 15\n",
      "Shape: [8]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 17:\n",
      "Name: arith.constant15\n",
      "Index: 16\n",
      "Shape: [2]\n",
      "Type: <class 'numpy.int32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 18:\n",
      "Name: sequential_1_1/conv2d_1/Relu;sequential_1_1/conv2d_1/add;sequential_1_1/conv2d_1/convolution;\n",
      "Index: 17\n",
      "Shape: [32  3  3  3]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 19:\n",
      "Name: sequential_1_1/conv2d_1/Relu;sequential_1_1/conv2d_1/add;sequential_1_1/conv2d_1/convolution;1\n",
      "Index: 18\n",
      "Shape: [ 1 26 26 32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 20:\n",
      "Name: sequential_1_1/max_pooling2d_1/MaxPool2d\n",
      "Index: 19\n",
      "Shape: [ 1 13 13 32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 21:\n",
      "Name: sequential_1_1/batch_normalization_1/batchnorm/mul_1\n",
      "Index: 20\n",
      "Shape: [ 1 13 13 32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 22:\n",
      "Name: sequential_1_1/batch_normalization_1/batchnorm/add_1\n",
      "Index: 21\n",
      "Shape: [ 1 13 13 32]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 23:\n",
      "Name: sequential_1_1/conv2d_1_2/Relu;sequential_1_1/conv2d_1_2/add;sequential_1_1/conv2d_1_2/convolution;\n",
      "Index: 22\n",
      "Shape: [ 1 11 11 64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 24:\n",
      "Name: sequential_1_1/max_pooling2d_1_2/MaxPool2d\n",
      "Index: 23\n",
      "Shape: [ 1  5  5 64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 25:\n",
      "Name: sequential_1_1/batch_normalization_1_2/batchnorm/mul_1\n",
      "Index: 24\n",
      "Shape: [ 1  5  5 64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 26:\n",
      "Name: sequential_1_1/batch_normalization_1_2/batchnorm/add_1\n",
      "Index: 25\n",
      "Shape: [ 1  5  5 64]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 27:\n",
      "Name: sequential_1_1/conv2d_2_1/Relu;sequential_1_1/conv2d_2_1/add;sequential_1_1/conv2d_2_1/convolution;\n",
      "Index: 26\n",
      "Shape: [  1   3   3 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 28:\n",
      "Name: sequential_1_1/max_pooling2d_2_1/MaxPool2d\n",
      "Index: 27\n",
      "Shape: [  1   1   1 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 29:\n",
      "Name: sequential_1_1/batch_normalization_2_1/batchnorm/mul_1\n",
      "Index: 28\n",
      "Shape: [  1   1   1 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 30:\n",
      "Name: sequential_1_1/batch_normalization_2_1/batchnorm/add_1\n",
      "Index: 29\n",
      "Shape: [  1   1   1 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 31:\n",
      "Name: sequential_1_1/flatten_1/Reshape\n",
      "Index: 30\n",
      "Shape: [  1 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 32:\n",
      "Name: sequential_1_1/dense_1/MatMul;sequential_1_1/dense_1/Relu;sequential_1_1/dense_1/Add\n",
      "Index: 31\n",
      "Shape: [  1 128]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n",
      "Layer 33:\n",
      "Name: StatefulPartitionedCall_1:0\n",
      "Index: 32\n",
      "Shape: [1 8]\n",
      "Type: <class 'numpy.float32'>\n",
      "Quantization: (0.0, 0)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def print_tflite_model_details(model_path):\n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    print(\"Model Architecture:\")\n",
    "    print(\"-------------------\")\n",
    "    print(\"Inputs:\")\n",
    "    for input_tensor in input_details:\n",
    "        print(f\"Name: {input_tensor['name']}\")\n",
    "        print(f\"Shape: {input_tensor['shape']}\")\n",
    "        print(f\"Type: {input_tensor['dtype']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"Outputs:\")\n",
    "    for output_tensor in output_details:\n",
    "        print(f\"Name: {output_tensor['name']}\")\n",
    "        print(f\"Shape: {output_tensor['shape']}\")\n",
    "        print(f\"Type: {output_tensor['dtype']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"Layers:\")\n",
    "    # Iterate through all tensors and extract layer information\n",
    "    for i in range(len(interpreter.get_tensor_details())):\n",
    "        tensor = interpreter.get_tensor_details()[i]\n",
    "        print(f\"Layer {i+1}:\")\n",
    "        print(f\"Name: {tensor['name']}\")\n",
    "        print(f\"Index: {tensor['index']}\")\n",
    "        print(f\"Shape: {tensor['shape']}\")\n",
    "        print(f\"Type: {tensor['dtype']}\")\n",
    "        print(f\"Quantization: {tensor['quantization']}\")\n",
    "        print(\"-------------------\")\n",
    "\n",
    "# Path to your TFLite model\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/ios_model.tflite'\n",
    "\n",
    "# Print the model details\n",
    "print_tflite_model_details(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall_1:0',\n",
       "  'index': 32,\n",
       "  'shape': array([1, 8]),\n",
       "  'shape_signature': array([-1,  8]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support.metadata_writers import image_classifier\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "\n",
    "# Paths to the model and label file\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/ios_model.tflite'\n",
    "label_file = 'C:/test001/ttt/cnn_classifier/ml_model/labels.txt'\n",
    "model_with_metadata_path = 'C:/test001/ttt/cnn_classifier/ml_model/ios_model_with_metadata.tflite'\n",
    "\n",
    "# Create a writer\n",
    "writer = image_classifier.MetadataWriter.create_for_inference(\n",
    "    writer_utils.load_file(model_path),\n",
    "    input_norm_mean=[127.5],\n",
    "    input_norm_std=[127.5],\n",
    "    label_file_paths=[label_file]\n",
    ")\n",
    "\n",
    "# Verify the metadata\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Write the metadata to the model file\n",
    "writer_utils.save_file(writer.populate(), model_with_metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflite_support'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_support\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata_writers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_classifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_support\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata_writers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m writer_utils\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_support\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflite_support'"
     ]
    }
   ],
   "source": [
    "from tflite_support.metadata_writers import image_classifier\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "from tflite_support import metadata\n",
    "\n",
    "# Paths to your model and the new model with metadata\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/model.tflite'\n",
    "output_model_path = 'C:/test001/ttt/cnn_classifier/ml_model/model_with_metadata.tflite'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the metadata writer\n",
    "writer = image_classifier.MetadataWriter.create_for_inference(\n",
    "    model_path=model_path,\n",
    "    label_file_paths=['C:/test001/ttt/cnn_classifier/notebook/label.txt'],\n",
    "    input_norm_mean=[0],  # Adjust these values if your model requires different normalization\n",
    "    input_norm_std=[255])\n",
    "\n",
    "# Write the metadata to the model\n",
    "writer_utils.save_file(writer.populate(), output_model_path)\n",
    "\n",
    "print(\"Metadata added and saved to\", output_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflite-support\n",
      "  Using cached tflite-support-0.1.0a1.tar.gz (390 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pybind11>=2.4 (from tflite-support)\n",
      "  Using cached pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\test001\\ttt\\lib\\site-packages (from tflite-support) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\test001\\ttt\\lib\\site-packages (from tflite-support) (1.26.3)\n",
      "Using cached pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
      "Building wheels for collected packages: tflite-support\n",
      "  Building wheel for tflite-support (pyproject.toml): started\n",
      "  Building wheel for tflite-support (pyproject.toml): finished with status 'error'\n",
      "Failed to build tflite-support\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tflite-support (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [74 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-312\n",
      "      creating build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      copying tflite_support\\codegen.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      copying tflite_support\\metadata.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      copying tflite_support\\metadata_schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      copying tflite_support\\schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      copying tflite_support\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      running egg_info\n",
      "      writing tflite_support.egg-info\\PKG-INFO\n",
      "      writing dependency_links to tflite_support.egg-info\\dependency_links.txt\n",
      "      writing entry points to tflite_support.egg-info\\entry_points.txt\n",
      "      writing requirements to tflite_support.egg-info\\requires.txt\n",
      "      writing top-level names to tflite_support.egg-info\\top_level.txt\n",
      "      reading manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      writing manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\Mind\\AppData\\Local\\Temp\\pip-build-env-om0v8g4p\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:215: _Warning: Package 'tflite_support.flatbuffers' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'tflite_support.flatbuffers' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'tflite_support.flatbuffers' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'tflite_support.flatbuffers' to be distributed and are\n",
      "              already explicitly excluding 'tflite_support.flatbuffers' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      copying tflite_support\\metadata_schema.fbs -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "      creating build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\builder.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\compat.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\encode.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\number_types.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\packer.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\table.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      copying tflite_support\\flatbuffers\\util.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "      running build_ext\n",
      "      building '_pywrap_codegen' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tflite-support\n",
      "ERROR: Could not build wheels for tflite-support, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 tflite-support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflite_support'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_support\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflite_support'"
     ]
    }
   ],
   "source": [
    "from tflite_support import metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set memory growth for GPUs\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "[{'name': 'serving_default_keras_tensor_220:0', 'index': 0, 'shape': array([ 1, 28, 28,  3]), 'shape_signature': array([-1, 28, 28,  3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Expected input shape: [ 1 28 28  3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/ios_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input details.\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Print input details.\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "\n",
    "# Extract and print the input shape.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"Expected input shape:\", input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      "[{'name': 'input_1', 'index': 15, 'shape': array([ 1, 28, 28,  1]), 'shape_signature': array([ 1, 28, 28,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Expected input shape: [ 1 28 28  1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "model_path = 'C:/test001/ttt/cnn_classifier/ml_model/model345.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input details.\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Print input details.\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "\n",
    "# Extract and print the input shape.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"Expected input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
