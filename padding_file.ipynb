{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_with_center_crop(image_path, target_size):\n",
    "    image = Image.open(image_path)\n",
    "    old_size = image.size\n",
    "    ratio = max(old_size) / float(target_size)\n",
    "    new_size = tuple([int(x / ratio) for x in old_size])\n",
    "    image = image.resize(new_size, Image.ANTIALIAS)\n",
    "    left = (new_size[0] - target_size) / 2\n",
    "    top = (new_size[1] - target_size) / 2\n",
    "    right = (new_size[0] + target_size) / 2\n",
    "    bottom = (new_size[1] + target_size) / 2\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    return cropped_image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'C:/test001/ttt/cnn_classifier/images/air.jpg'\n",
    "target_size = 28  # Specify the target size as a single integer for square cropping\n",
    "cropped_image = resize_with_center_crop(image_path, target_size)\n",
    "\n",
    "# Display the cropped image (optional)\n",
    "cropped_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def resize_with_padding(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = ImageOps.invert(image)  # Invert colors if needed\n",
    "    old_size = image.size\n",
    "    ratio = float(target_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    image = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    new_image = Image.new(\"L\", (target_size, target_size), 0)  # Create new image with black padding\n",
    "    new_image.paste(image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'C:/test001/ttt/cnn_classifier/iamges/air.jpg'\n",
    "target_size = 28  # Specify the target size as a single integer for square cropping\n",
    "padded_image = resize_with_padding(image_path, target_size)\n",
    "\n",
    "# Convert to NumPy array and ensure shape is (28, 28, 1)\n",
    "image_array1 = np.array(padded_image)\n",
    "image_array1 = np.expand_dims(image_array1, axis=-1)\n",
    "\n",
    "print(np.shape(image_array1))  # Should output (28, 28, 1)\n",
    "padded_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def resize_with_padding1(image_path, target_size):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    image = ImageOps.invert(image)\n",
    "    old_size = image.size\n",
    "    ratio = float(target_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    image = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    new_image = Image.new(\"RGB\", (target_size, target_size), (0, 0, 0))\n",
    "    new_image.paste(image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "    return new_image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'C:/test001/ttt/cnn_classifier/iamges/air.jpg'\n",
    "target_size = 28  # Specify the target size as a single integer for square cropping\n",
    "padded_image = resize_with_padding1(image_path, target_size)\n",
    "\n",
    "np.shape(padded_image)\n",
    "# Display the padded image (optional)\n",
    "padded_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m chromedriver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Mind/Downloads/driver/chromedriver-win64/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a new instance of the Chrome driver\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchromedriver_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Go to a website\u001b[39;00m\n\u001b[0;32m     12\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.google.com\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Set the path to the chromedriver executable\n",
    "chromedriver_path = 'C:/Users/Mind/Downloads/driver/chromedriver-win64/chromedriver'\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_path)\n",
    "\n",
    "# Go to a website\n",
    "driver.get(\"http://www.google.com\")\n",
    "\n",
    "# Find the search box\n",
    "search_box = driver.find_element(By.NAME, \"q\")\n",
    "\n",
    "# Type a search query\n",
    "search_box.send_keys(\"OpenAI\")\n",
    "\n",
    "# Press Enter\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the results to load and display the title\n",
    "driver.implicitly_wait(5)  # seconds\n",
    "print(driver.title)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 1, 28, 28)\n",
      "X_test shape: (2000, 1, 28, 28)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of file paths for the 10 classes\n",
    "file_paths = [\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_basketball.npy',\n",
    "    'C:/demo/classfier_cnn/data/full_numpy_bitmap_airplane.npy'\n",
    "]\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(file_paths, num_samples=5000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        array_data = np.load(file_path)\n",
    "        # Get the first num_samples samples\n",
    "        first_samples = array_data[:num_samples]\n",
    "        data.append(first_samples)\n",
    "        # Create labels for these samples\n",
    "        labels.append(np.full((num_samples,), idx))\n",
    "    return np.vstack(data), np.concatenate(labels)\n",
    "\n",
    "# Load the data\n",
    "data, labels = load_data(file_paths)\n",
    "\n",
    "# Normalize the data\n",
    "data = data.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the data if necessary (e.g., if the images are 28x28 pixels)\n",
    "data = data.reshape(-1, 1,28, 28)  # Assuming the images are 28x28 pixels and grayscale\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'full_numpy_bitmap_basketball', 1: 'full_numpy_bitmap_airplane'}\n"
     ]
    }
   ],
   "source": [
    "class_labels = [\n",
    "    'full_numpy_bitmap_basketball',\n",
    "    'full_numpy_bitmap_airplane'\n",
    "]\n",
    "\n",
    "# Create the dictionary\n",
    "class_dict = {i: label for i, label in enumerate(class_labels)}\n",
    "\n",
    "# Print the dictionary\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after reshaping: torch.Size([8000, 1, 28, 28])\n",
      "X_test shape after reshaping: torch.Size([2000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_test_reshaped = np.reshape(X_test, (2000, 1, 28, 28))\n",
    "X_train_reshaped = np.reshape(X_train, (8000, 1, 28, 28))\n",
    "\n",
    "# Print the shape after reshaping\n",
    "print(\"X_train shape after reshaping:\", X_train_reshaped.shape)\n",
    "print(\"X_test shape after reshaping:\", X_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assume X_train, y_train, X_test, y_test are already defined as numpy arrays or tensors\n",
    "\n",
    "# Convert data to tensors if they are numpy arrays\n",
    "if isinstance(X_train_reshaped, np.ndarray):\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32) #dtype=torch.float32\n",
    "if isinstance(y_train, np.ndarray):\n",
    "    y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "if isinstance(X_test_reshaped, np.ndarray):\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "if isinstance(y_test, np.ndarray):\n",
    "    y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "# Combine data and labels into TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_dataset, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000235BA889DF0>, <torch.utils.data.dataloader.DataLoader object at 0x000002347FCA9400>)\n",
      "Length of train dataloader: 250 batches of 32\n",
      "Length of test dataloader: 63 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\test001\\ttt\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "  3%|▎         | 1/30 [00:03<01:36,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.1569 | Test Loss: 0.1479 | Test Acc: 97.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:06<01:27,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 0.0902 | Test Loss: 0.0489 | Test Acc: 98.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:09<01:23,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.0724 | Test Loss: 0.0527 | Test Acc: 98.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:12<01:20,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.0647 | Test Loss: 0.0419 | Test Acc: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:15<01:17,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | Train Loss: 0.0678 | Test Loss: 0.0387 | Test Acc: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:18<01:14,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | Train Loss: 0.0563 | Test Loss: 0.0389 | Test Acc: 98.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:21<01:11,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | Train Loss: 0.0494 | Test Loss: 0.0446 | Test Acc: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:24<01:08,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | Train Loss: 0.0474 | Test Loss: 0.0500 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:27<01:05,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | Train Loss: 0.0445 | Test Loss: 0.0699 | Test Acc: 98.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:31<01:01,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | Train Loss: 0.0425 | Test Loss: 0.2963 | Test Acc: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:34<00:58,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | Train Loss: 0.0395 | Test Loss: 0.0993 | Test Acc: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:37<00:55,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | Train Loss: 0.0410 | Test Loss: 0.1093 | Test Acc: 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:40<00:52,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | Train Loss: 0.0358 | Test Loss: 0.0407 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:43<00:49,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | Train Loss: 0.0339 | Test Loss: 0.0952 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:46<00:45,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | Train Loss: 0.0344 | Test Loss: 0.0857 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:49<00:43,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | Train Loss: 0.0305 | Test Loss: 0.0526 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:52<00:40,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | Train Loss: 0.0311 | Test Loss: 0.1533 | Test Acc: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:55<00:37,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | Train Loss: 0.0297 | Test Loss: 0.0367 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:58<00:34,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 | Train Loss: 0.0263 | Test Loss: 0.1136 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [01:01<00:30,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 | Train Loss: 0.0329 | Test Loss: 0.0720 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [01:04<00:27,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 | Train Loss: 0.0292 | Test Loss: 0.0383 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:07<00:24,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 | Train Loss: 0.0304 | Test Loss: 0.0739 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [01:11<00:21,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 | Train Loss: 0.0257 | Test Loss: 0.0580 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [01:14<00:18,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 | Train Loss: 0.0294 | Test Loss: 0.3690 | Test Acc: 98.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [01:17<00:15,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 | Train Loss: 0.0272 | Test Loss: 0.0571 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [01:20<00:12,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 | Train Loss: 0.0332 | Test Loss: 0.0615 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [01:23<00:09,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 | Train Loss: 0.0264 | Test Loss: 0.3400 | Test Acc: 98.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [01:26<00:06,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 | Train Loss: 0.0283 | Test Loss: 0.0645 | Test Acc: 98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [01:29<00:03,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 | Train Loss: 0.0314 | Test Loss: 0.0858 | Test Acc: 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:32<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 | Train Loss: 0.0278 | Test Loss: 0.0757 | Test Acc: 98.81%\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class DoodleClassModel04(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128*3*3, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features=256, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    return (correct / len(y_true)) * 100\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = DoodleClassModel04(input_channels=1, output_shape=len(class_dict)) # For grayscale images\n",
    "model_2.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model_2.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, verbose=True)\n",
    "\n",
    "# Data loading (assuming train_dataloader and test_dataloader are defined)\n",
    "epochs = 30\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model_2.train()\n",
    "    train_loss = 0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model_2(X)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    scheduler.step(test_loss)  # Update the scheduler\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_sample_image(image_array):\n",
    "    # Normalize the image\n",
    "    image_array = image_array.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape the image to (1, 1, 28, 28) if it's a single image\n",
    "    image_array = np.reshape(image_array, (1, 1, 28, 28))\n",
    "    \n",
    "    # Convert to torch tensor\n",
    "    image_tensor = torch.tensor(image_array, dtype=torch.float32)\n",
    "    \n",
    "    # Check if CUDA (GPU) is available and move tensor to CUDA device\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cpu'#torch.device(\"cuda\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(678, 834)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('C:/test001/ttt/cnn_classifier/iamges/air.jpg').convert('L')  # Convert to grayscale\n",
    "\n",
    "# Invert the colors\n",
    "image = ImageOps.invert(image)\n",
    "print(np.shape(image))\n",
    "# Resize the image to 28x28\n",
    "resized_image = image.resize((28, 28))\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(resized_image)\n",
    "\n",
    "# Ensure the image has the shape (28, 28, 1)\n",
    "image_array = np.expand_dims(image_array, axis=-1)\n",
    "\n",
    "print(np.shape(image_array))  # Should output (28, 28, 1)\n",
    "plt.imshow(image_array.squeeze(), cmap='gray')\n",
    "plt.axis('off')  # Optional: to hide the axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: full_numpy_bitmap_airplane\n",
      "Predicted class index: 1\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the sample image\n",
    "sample_image_tensor = preprocess_sample_image(image_array)#(input_tensor)\n",
    "\n",
    "# Make a prediction with the loaded model\n",
    "with torch.no_grad():\n",
    "    output = model_2(sample_image_tensor)\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "# Print the predicted class\n",
    "\n",
    "print(f\"Predicted class label: {class_dict[predicted_class]}\")\n",
    "print(f\"Predicted class index: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2.state_dict(), './models/cnn_noncuda_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
